{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v83UWZ66ui2",
        "outputId": "4ee935dc-b6b6-4c04-b55e-d523d517ae77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: hii\n",
            "Response: Aata Kay msg kartoy\n",
            "\n",
            "Message: my new no.\n",
            "Response: Okay\n",
            "\n",
            "Message: okay\n",
            "Response: download hotay thamb\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import numpy as np\n",
        "import emoji\n",
        "import string\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and preprocess the text data.\"\"\"\n",
        "    # Remove emoji characters\n",
        "    text = emoji.replace_emoji(text, '')\n",
        "    # Remove punctuation except periods and question marks\n",
        "    text = ''.join(ch for ch in text if ch not in string.punctuation or ch in '.?')\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text.strip()\n",
        "\n",
        "def parse_whatsapp_txt(file_path):\n",
        "    \"\"\"Parse WhatsApp chat from a txt file into a structured format.\"\"\"\n",
        "    # Regular expression for WhatsApp message format\n",
        "    pattern = r'(\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}(?:\\s?[AaPpMm]{2})?)\\s-\\s([^:]+):\\s(.+)'\n",
        "\n",
        "    messages = []\n",
        "    current_message = ''\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                match = re.match(pattern, line.strip())\n",
        "                if match:\n",
        "                    # If we find a new message, save the previous one (if any)\n",
        "                    if current_message:\n",
        "                        messages.append(current_message)\n",
        "                    # Start a new message\n",
        "                    timestamp, sender, message = match.groups()\n",
        "                    current_message = {\n",
        "                        'timestamp': timestamp,\n",
        "                        'sender': sender.strip(),\n",
        "                        'message': preprocess_text(message.strip())\n",
        "                    }\n",
        "                elif current_message:\n",
        "                    # Append continued message text\n",
        "                    current_message['message'] += ' ' + preprocess_text(line.strip())\n",
        "\n",
        "            # Add the last message\n",
        "            if current_message:\n",
        "                messages.append(current_message)\n",
        "\n",
        "    except UnicodeDecodeError:\n",
        "        # Try with different encoding if utf-8 fails\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            # Repeat the same process...\n",
        "            for line in file:\n",
        "                match = re.match(pattern, line.strip())\n",
        "                if match:\n",
        "                    if current_message:\n",
        "                        messages.append(current_message)\n",
        "                    timestamp, sender, message = match.groups()\n",
        "                    current_message = {\n",
        "                        'timestamp': timestamp,\n",
        "                        'sender': sender.strip(),\n",
        "                        'message': preprocess_text(message.strip())\n",
        "                    }\n",
        "                elif current_message:\n",
        "                    current_message['message'] += ' ' + preprocess_text(line.strip())\n",
        "\n",
        "            if current_message:\n",
        "                messages.append(current_message)\n",
        "\n",
        "    return pd.DataFrame(messages)\n",
        "\n",
        "class WhatsAppChatbot:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=1000,\n",
        "            stop_words='english',\n",
        "            ngram_range=(1, 2)\n",
        "        )\n",
        "        self.classifier = MultinomialNB()\n",
        "        self.responses = {}\n",
        "        self.common_responses = {}\n",
        "\n",
        "    def train(self, chat_df, target_user):\n",
        "        \"\"\"Train the chatbot on WhatsApp chat data for a specific user.\"\"\"\n",
        "        # Get conversation pairs (previous message and response)\n",
        "        conversation_pairs = []\n",
        "        labels = []\n",
        "\n",
        "        # Build response patterns\n",
        "        for i in range(1, len(chat_df)):\n",
        "            prev_message = chat_df.iloc[i-1]['message'].lower()\n",
        "            current_message = chat_df.iloc[i]['message']\n",
        "            current_sender = chat_df.iloc[i]['sender']\n",
        "\n",
        "            if current_sender == target_user:\n",
        "                conversation_pairs.append(prev_message)\n",
        "                labels.append(current_message)\n",
        "\n",
        "                # Store response patterns\n",
        "                if prev_message in self.responses:\n",
        "                    if current_message not in self.responses[prev_message]:\n",
        "                        self.responses[prev_message].append(current_message)\n",
        "                else:\n",
        "                    self.responses[prev_message] = [current_message]\n",
        "\n",
        "                # Track common responses\n",
        "                if current_message in self.common_responses:\n",
        "                    self.common_responses[current_message] += 1\n",
        "                else:\n",
        "                    self.common_responses[current_message] = 1\n",
        "\n",
        "        # Transform messages to TF-IDF features\n",
        "        if conversation_pairs:\n",
        "            X = self.vectorizer.fit_transform(conversation_pairs)\n",
        "            y = [1] * len(labels)\n",
        "            self.classifier.fit(X, y)\n",
        "\n",
        "    def respond(self, message):\n",
        "        \"\"\"Generate a response to a given message.\"\"\"\n",
        "        message = preprocess_text(message.lower())\n",
        "\n",
        "        # Direct match\n",
        "        if message in self.responses:\n",
        "            return np.random.choice(self.responses[message])\n",
        "\n",
        "        # Try to find similar messages\n",
        "        try:\n",
        "            message_vector = self.vectorizer.transform([message])\n",
        "            similarity_scores = self.classifier.predict_proba(message_vector)[0]\n",
        "\n",
        "            if max(similarity_scores) > 0.2:  # Similarity threshold\n",
        "                # Find messages with similar patterns\n",
        "                for trained_message in self.responses:\n",
        "                    if (message in trained_message or\n",
        "                        trained_message in message or\n",
        "                        any(word in trained_message.split() for word in message.split())):\n",
        "                        return np.random.choice(self.responses[trained_message])\n",
        "\n",
        "            # If no good match, return most common relevant response\n",
        "            return max(self.common_responses.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        except (ValueError, AttributeError):\n",
        "            return \"I'm not sure how to respond to that.\"\n",
        "\n",
        "def create_chatbot_from_txt(file_path, target_user):\n",
        "    \"\"\"Create and train a chatbot from a WhatsApp chat txt file.\"\"\"\n",
        "    # Parse chat data\n",
        "    chat_df = parse_whatsapp_txt(file_path)\n",
        "\n",
        "    # Create and train chatbot\n",
        "    chatbot = WhatsAppChatbot()\n",
        "    chatbot.train(chat_df, target_user)\n",
        "\n",
        "    return chatbot\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create chatbot from txt file\n",
        "    file_path = 'whatsapp_chat.txt'  # Replace with your chat file path\n",
        "    chatbot = create_chatbot_from_txt(file_path, \"Rohan Sadaphule\")\n",
        "\n",
        "    # Test the chatbot\n",
        "    test_messages = [\"hii\", \"my new no.\", \"okay\"]\n",
        "    for message in test_messages:\n",
        "        response = chatbot.respond(message)\n",
        "        print(f\"Message: {message}\")\n",
        "        print(f\"Response: {response}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bCBodWTVy-3",
        "outputId": "21f40f79-e562-4114-ce97-35a7737fa14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/586.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/586.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chat with the person/bot\n",
        "while True:\n",
        "    message=input(\"Enter your msg: \")\n",
        "    response = chatbot.respond(message)\n",
        "    print(response)\n",
        "    if message.lower() == 'exit':\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaAlA45b7wy2",
        "outputId": "58a2a213-e5d8-487c-ce95-7176079a8a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your msg: Hello\n",
            "Kasa gela interview\n",
            "Enter your msg: Konta interview\n",
            "Cusrow Wadia\n",
            "Enter your msg: Clg la yetoy ka\n",
            "\n",
            "Enter your msg: Udya jaycha ka?\n",
            "Lavkar sang ticket kadhaycha kaltay\n",
            "Enter your msg: Exit\n",
            "Thik aahe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BGMI750Y_Qms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LkdRyzLW_RNr"
      }
    }
  ]
}